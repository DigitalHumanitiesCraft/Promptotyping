# Promptotyping

<p class="subtitle">Ein Praxisbericht zur strukturierten LLM-assistierten Entwicklung in den Digital Humanities</p>

---

<div class="paper-meta-card">
  <div class="meta-abstract">
    <h3>Abstract</h3>
    <p class="abstract-short">
      Large Language Models transformieren die Softwareentwicklung fundamental. Dieser Praxisbericht pr√§sentiert <strong>Promptotyping</strong> als strukturierten Ansatz f√ºr explorative Entwicklung in den Digital Humanities. Die Methode entstand iterativ aus sieben Projekten √ºber f√ºnf Monate und operiert in sechs dokumentierten Phasen mit Expertenvalidierung.
    </p>
    <div class="abstract-full" id="abstract-full" style="display: none;">
      <p>
        W√§hrend GitHub Copilot Studien allgemeine Produktivit√§tssteigerungen dokumentieren und wissenschaftliche Publikationen zu LLM-assistierter Entwicklung von 7 (2020) auf √ºber 160 (2023) stiegen, fehlen strukturierte Methoden f√ºr den wissenschaftlichen Einsatz. Das "Vibe Coding" erm√∂glicht zwar schnelles Prototyping durch vague Prompts, f√ºhrt jedoch zu undokumentierten Systemen deren sp√§tere Nachvollziehbarkeit problematisch ist.
      </p>
      <p>
        Die Validierung erfolgte mehrstufig durch technische Expertenpr√ºfung, fachliche Dom√§nenvalidierung sowie automatisierte Verifikation. Verschiedene LLMs wurden entsprechend ihrer beobachteten St√§rken eingesetzt. Ein strukturiertes Journal dokumentiert den Entwicklungsprozess und bewahrt erfolgreiche Prompt-Patterns.
      </p>
      <p>
        Die Projekte variierten von zweist√ºndigen Proof-of-Concepts bis zu 25-st√ºndigen digitalen Editionen. In unserer Erfahrung zeigten Projekte mit f√ºnf bis sieben Dokumenten die beste Balance zwischen Struktur und Flexibilit√§t. Workshop-Teilnehmer ohne Programmiererfahrung erstellten funktionale Prototypen in sechs bis acht Stunden.
      </p>
      <p>
        Promptotyping adressiert spezifische LLM-Herausforderungen durch phasenweise Dokumentaufteilung und mehrstufige Validierung. Die Methode macht implizites Wissen explizit und teilbar. Sie systematisiert die explorative Entwicklung mit LLMs und erm√∂glicht niedrigschwellige technische Entwicklung bei gleichzeitiger Wahrung wissenschaftlicher Standards durch strukturierte Dokumentation.
      </p>
    </div>
    <button class="read-more-btn" onclick="toggleAbstract()">Mehr lesen ‚Üí</button>
  </div>

  <div class="meta-actions">
    <a href="https://github.com/chpollin/Promptotyping/raw/main/paper-draft.pdf" class="meta-btn primary" target="_blank" rel="noopener">
      <span class="btn-icon">üìÑ</span>
      <span>PDF Download</span>
    </a>
    <a href="https://github.com/chpollin/Promptotyping" class="meta-btn" target="_blank" rel="noopener">
      <span class="btn-icon">üíª</span>
      <span>GitHub Repository</span>
    </a>
    <a href="https://github.com/chpollin/Promptotyping/tree/main/use%20cases" class="meta-btn" target="_blank" rel="noopener">
      <span class="btn-icon">üì¶</span>
      <span>Data & Attachments</span>
    </a>
  </div>

  <div class="meta-info">
    <div class="info-item">
      <span class="info-label">Autor:</span>
      <span>Christopher Pollin</span>
    </div>
    <div class="info-item">
      <span class="info-label">Zeitraum:</span>
      <span>Oktober 2024 - Januar 2025</span>
    </div>
    <div class="info-item">
      <span class="info-label">Projekte:</span>
      <span>7 Digital Humanities Anwendungen</span>
    </div>
    <div class="info-item">
      <span class="info-label">Methode:</span>
      <span>6-Phasen Promptotyping Prozess</span>
    </div>
  </div>
</div>

---

## 1. Einleitung

Digital Humanities-Forschende ben√∂tigen spezialisierte digitale Werkzeuge f√ºr hochspezifische Forschungsfragen, verf√ºgen aber selten √ºber Ressourcen f√ºr professionelle Softwareentwicklung. Large Language Models versprechen hier niedrigschwellige Code-Generierung. Die Erfahrung zeigt jedoch, dass undokumentierte Entwicklung die sp√§tere Nachvollziehbarkeit erschwert.

Andrej Karpathy pr√§gte den Begriff "Vibe Coding" f√ºr diese intuitive Entwicklungspraxis, bei der Code durch vage Prompts generiert und ohne tieferes Verst√§ndnis akzeptiert wird. Er warnt, dass man sich regelm√§√üig ehrlich fragen solle, ob man wirklich noch verstehe, was gerade passiert. Diese Warnung ist besonders relevant f√ºr wissenschaftliche Anwendungen, wo Nachvollziehbarkeit und Reproduzierbarkeit zentral sind.

Dieser Praxisbericht pr√§sentiert Promptotyping als pragmatische Alternative. Die Methode entstand iterativ aus der praktischen Arbeit an sieben DH-Projekten. Sie systematisiert die Interaktion mit LLMs ohne den Overhead traditioneller Softwareentwicklung.

Als Praxisbericht dokumentiert diese Arbeit bew√§hrte Praktiken aus realen Projekten ohne Anspruch auf empirische Validierung. Die beschriebenen Muster und Beobachtungen entstanden aus der Projektpraxis und sind als Orientierungshilfe f√ºr √§hnliche Vorhaben gedacht.

---

## 2. Entwicklung des Ansatzes

### 2.1 Praktische Erfahrungen

Zwischen Oktober 2024 und Januar 2025 entwickelten wir iterativ die Promptotyping-Methode anhand von sieben Digital Humanities-Projekten.

<div class="use-case-placeholder" data-id="szd"></div>

**Stefan Zweig Digital** (2h) testete minimalen Ansatz ohne Dokumentation. Das Timeline-Tool f√ºr die digitale Nachlassrekonstruktion funktionierte initial, war aber nach zwei Wochen selbst f√ºr den Entwickler schwer nachvollziehbar. Dieses Experiment demonstrierte die Grenzen des reinen "Vibe Coding".

<div class="use-case-placeholder" data-id="realonline"></div>

**REALonline Rauminventare** (5h, 6 Dokumente) visualisierte mittelalterliche Objektverteilungen in √∂sterreichischen Adelsh√§usern von 1432 bis 1602. Die strukturierte Dokumentation erm√∂glichte erfolgreiche Iteration nach Expertenintervention. Der Historiker korrigierte unsere technischen Annahmen √ºber Objekthierarchien und pr√§ferierte historische Begriffe statt moderner Kategorien.

<div class="use-case-placeholder" data-id="aldersbach"></div>

**Aldersbach Kloster** (8h, 7 Dokumente) integrierte heterogene Quelltypen in ein Annotationstool. Die systematische DATA-Phase half bei der Normalisierung inkonsistenter Datenformate aus verschiedenen Archivbest√§nden.

<div class="use-case-placeholder" data-id="cvma"></div>

**CVMA Glasfenster** (8h, 5 Dokumente) demonstrierte erfolgreiche Mensch-KI-Kollaboration beim Corpus Vitrearum Medii Aevi. SPARQL-Queries f√ºr den NFDI4Culture Knowledge Graph entstanden in drei Iterationsschleifen zwischen menschlicher Validierung und LLM-Optimierung. Die 29MB JSON-LD Verarbeitung erforderte Python-Preprocessing.

<div class="use-case-placeholder" data-id="km"></div>

**Kriminalmuseum** (10h, 3 Dokumente) entwickelte ein digitales Archiv der Hans Gross Sammlung mit 3.892 Objekten. Mit nur DATA.md, DESIGN.md und README.md entstand zwar ein funktionales Dual-Interface mit traditioneller Suche und Canvas-Explorer, die fehlende IMPLEMENTATION.md erschwerte jedoch sp√§tere Anpassungen.

<div class="use-case-placeholder" data-id="lucina"></div>

**Lucina Edition** (25h, 11+ Dokumente) entwickelte eine TEI-konforme digitale Edition des Madrid BN Mss. 6028 mit 128 neulateinischen Gedichten. F√ºnf dokumentierte Iterationen f√ºhrten von der Basis-Konversion bis zur vollst√§ndigen Edition mit Prosopographie und metrischer Analyse. Die hohe Dokumentenanzahl machte Koordination zunehmend komplex.

**REALonline Iteration 2** (8h, 7 Dokumente) validierte die verbesserte Methode. Mit vollst√§ndigem Dokumentsatz und aktivem JOURNAL.md entstand eine robustere Architektur mit besserer Treemap-Visualisierung.

| Projekt | Zeit | Dokumente | Ergebnis | Erkenntnisse | Verf√ºgbarkeit¬π |
|---------|------|-----------|----------|--------------|----------------|
| Stefan Zweig Digital | 2h | 0 | Timeline-Tool | Ohne Struktur schwer wartbar | [Demo](https://dhcraft.org/excellence/promptotyping/szd-annotation-timeline/) |
| REALonline v1 | 5h | 6 | Interaktive Visualisierung | Expertenvalidierung kritisch | [Demo](https://chpollin.github.io/imareal-room-object/) |
| Aldersbach Kloster | 8h | 7 | Annotationstool | DATA-Phase zentral f√ºr heterogene Quellen | - |
| CVMA Glasfenster | 8h | 5 | Viewer mit Metadaten | Co-Intelligence Pattern erfolgreich | [Demo](https://chpollin.github.io/stained-glass-metadata-annotation-tool/) |
| Kriminalmuseum | 10h | 3 | Dual-Interface | Minimaldokumentation problematisch | [Demo](https://chpollin.github.io/km/) |
| Lucina Edition | 25h | 11+ | Digitale Edition (5 Versionen) | Koordination wird komplex | [Demo](https://chpollin.github.io/diged-neolat/) |
| REALonline v2 | 8h | 7 | Verbesserte Architektur | JOURNAL.md wertvoll | siehe v1 |

¬π Vollst√§ndige Repositories und Dokumentation unter github.com/chpollin/

### 2.2 Kernerkenntnisse aus der Projektpraxis

In unserer Erfahrung zeigten Projekte mit f√ºnf bis sieben Dokumenten optimale Balance zwischen Struktur und Agilit√§t. Unter f√ºnf Dokumenten litt die Nachvollziehbarkeit (Stefan Zweig Digital, Kriminalmuseum), √ºber zehn Dokumente erschwerten die Navigation (Lucina Edition).

Die IMPLEMENTATION-Phase mit expliziter Dokumentation von Datentransformationen half, typische Fehlerquellen zu vermeiden. Im REALonline-Projekt verhinderte die dokumentierte Normalisierung inkonsistenter JSON-Typen sp√§tere Laufzeitfehler. Das JOURNAL.md erm√∂glichte Wiederaufnahme nach Pausen und Wissenstransfer zwischen Entwicklern.

---

## 3. Die Promptotyping-Methode

### 3.1 Phasenmodell

Promptotyping strukturiert die Entwicklung in sechs konsekutive Phasen.

**CONTEXT (README.md)** erfasst Projektziele und Constraints. Diese Phase definiert Zielgruppe, Anwendungskontext und technische Rahmenbedingungen.

**DATA (DATA.md)** spezifiziert Datenstrukturen, Schnittstellen und Beziehungen. Bei komplexen Projekten entstehen multiple Datendokumente. Die CVMA-Datenanalyse dokumentierte beispielsweise JSON-LD Strukturen mit verschachtelten Metadaten √ºber 600 Zeilen.

**EXPLORATION** ist eine experimentelle Phase ohne formale Dokumentation. Entwickler testen verschiedene Technologien, UI-Konzepte oder Algorithmen. Diese Phase kl√§rt technische Machbarkeit und identifiziert unerwartete Herausforderungen.

**REQUIREMENTS (REQUIREMENTS.md)** formalisiert funktionale und nicht-funktionale Anforderungen basierend auf den Explorationsergebnissen.

**IMPLEMENTATION (INSTRUCTIONS.md)** entwickelt detaillierte Anweisungen und Designspezifikationen. Diese Phase dokumentiert alle Datentransformationen, Validierungen und Algorithmen. Sie erwies sich in unserer Erfahrung als kritisch f√ºr die Fehlervermeidung.

**PROTOTYPE** generiert den finalen Code basierend auf INSTRUCTIONS.md.

Optional kann zwischen Requirements und Implementation eine Design-Phase eingef√ºgt werden, in der Fachexperten visuelle und interaktive Aspekte spezifizieren. Die Phasen k√∂nnen je nach Problemtyp auch flie√üend ineinander √ºbergehen oder angepasst werden.

### 3.2 Savepoints und Dokumentstruktur

Jede Phase fungiert als Savepoint mit erfolgreich validiertem Meilenstein. Der √úbergang zum n√§chsten Savepoint erfolgt erst nach Expertenfreigabe. Bei Problemen wird die Phase wiederholt, nicht der Savepoint revidiert.

Die Dokumentation operiert auf zwei Ebenen. Ergebnisdokumente dokumentieren was gebaut wurde mit README.md f√ºr Projektziele, DATA.md f√ºr Datenstrukturen, REQUIREMENTS.md f√ºr formale Anforderungen und INSTRUCTIONS.md f√ºr Implementierungsanweisungen. Die Prozessdokumentation erfasst wie und warum gebaut wurde durch ein fortlaufendes JOURNAL.md und optional eine kuratierte PROMPTS.md Bibliothek.

### 3.3 Dokumentation als externes Arbeitsged√§chtnis

LLMs haben kein persistentes Ged√§chtnis zwischen Konversationen. Die Markdown-Dokumente fungieren als externes Arbeitsged√§chtnis. Jedes Dokument hat einen spezifischen Fokus und vermeidet Redundanz. Querverweise zwischen Dokumenten sind explizit. Die modulare Struktur erm√∂glicht selektiven Kontext je nach Aufgabe.

### 3.4 Das Promptotyping Journal

Das Journal dokumentiert den kontinuierlichen Entwicklungsprozess als narratives Protokoll. Es wird LLM-unterst√ºtzt w√§hrend der Entwicklung generiert und erfasst die Evolution von Prompts, Modellentscheidungen und Lernerfahrungen. Ein strukturiertes Template gew√§hrleistet Konsistenz √ºber Projekte hinweg. Im REALonline-Projekt dokumentierte das Journal beispielsweise die kritische Entscheidung, Hierarchien nach Geb√§uden statt Objektkategorien zu strukturieren.

### 3.5 Mehrstufige Validierung

Die Validierung erfolgte in unseren Projekten auf mehreren Ebenen.

**Technische Validierung** pr√ºft Code-Qualit√§t, Performance und Sicherheit durch den Entwickler.

**Fachliche Validierung** bewertet die inhaltliche Korrektheit durch Dom√§nenexperten. Im REALonline-Projekt korrigierte der Historiker unsere Annahme √ºber Objekthierarchien. Bei CVMA validierte der Kunsthistoriker die korrekte Erfassung ikonographischer Metadaten.

**LLM-as-Judge** nutzt ein zweites Modell zur Pr√ºfung des generierten Codes auf spezifische Probleme.

**Multi-Model Council** konsultiert bei kritischen Entscheidungen mehrere Modelle. Konsens f√ºhrt zum Proceed, Dissens triggert menschliche Entscheidung.

Im CVMA-Projekt entwickelten wir SPARQL-Queries iterativ durch Co-Intelligence. Der Mensch identifizierte fehlende Felder, das LLM erg√§nzte die Query, der Mensch validierte gegen die Datenbank. Diese Schleife ben√∂tigte drei Iterationen bis zur optimalen Query mit geografischen Daten und Performance-Optimierung.

---

## 4. Fallstudie: REALonline Rauminventare

### 4.1 Projektkontext

Die REALonline-Datenbank der Universit√§t Salzburg dokumentiert materielle Kultur des Mittelalters. Unser Projekt sollte Rauminventare √∂sterreichischer Adelssitze von 1432 bis 1602 visualisieren.

### 4.2 Entwicklungsverlauf

Die **CONTEXT-Phase** (30 Min) kl√§rte die Forschungsfrage mit dem Historiker. Der Fokus lag auf sozialen Hierarchien durch Objektverteilung in R√§umen.

Die **DATA-Phase** (1h) analysierte den JSON-Export aus Neo4j. Wir entdeckten inkonsistente Datentypen, bei denen manche Felder sowohl als String als auch als Array auftraten.

Die **EXPLORATION** (2h) brachte eine √úberraschung. Statt einer Sammlung fanden wir multiple separate Inventare verschiedener Adelssitze. Eine komplette Neukonzeption war n√∂tig.

In der **REQUIREMENTS-Phase** (45 Min) priorisierte der Historiker Timeline-Visualisierung h√∂her als urspr√ºnglich angenommen.

Die **DESIGN-Phase** (30 Min) brachte spezifische Vorgaben des Historikers. Er pr√§ferierte Graut√∂ne statt Farben f√ºr wissenschaftliche Publikation, ein dreispaltiges Layout und verz√∂gerte Hover-Effekte.

Die **IMPLEMENTATION** (45 Min) dokumentierte alle Normalisierungen und Transformationen pr√§zise. Dies verhinderte sp√§ter Fehler bei der Array-String-Konversion.

Der **PROTOTYPE** ben√∂tigte vier Iterationen (90 Min). Der Treemap-Algorithmus produzierte zun√§chst unleserlich schmale Bereiche. Die L√∂sung war die Aggregation kleiner Gruppen unter "Weitere".

### 4.3 Kritische Intervention

Der Historiker korrigierte mehrere technische Annahmen. Die Hierarchie sollte nach Geb√§uden erfolgen, nicht nach Objektkategorien. Historische Begriffe aus nomenclature_original waren statt moderner Kategorien zu verwenden. Die dezente Visualisierung war f√ºr wissenschaftliche Publikation essentiell.

Diese Interventionen waren nur durch kontinuierliche Experteneinbindung m√∂glich. Das strukturierte Journal dokumentierte alle Entscheidungen und erm√∂glichte sp√§tere Nachvollziehbarkeit.

---

## 5. Workshop-Validierung

Drei Workshops mit insgesamt 24 Teilnehmern aus Geschichtswissenschaft, Literaturwissenschaft und Arch√§ologie testeten die √úbertragbarkeit. Das Setup umfasste VS Code, Python und kostenlose LLM-Zug√§nge. Im Zeitrahmen von sechs bis acht Stunden erstellten 20 von 24 Teilnehmern funktionale Prototypen.

Beobachtete Herausforderungen waren die Tendenz, Phasen zu √ºberspringen, besonders die IMPLEMENTATION-Phase. Teilnehmer √ºberforderten LLMs mit zu viel Kontext gleichzeitig und vernachl√§ssigten die Savepoint-Validierung.

Erfolgreiche Strategien umfassten explizite Referenzierung vorheriger Dokumente in Prompts, regelm√§√üige Zwischenvalidierung an Phasen√ºberg√§ngen und Git-Commits nach jedem validierten Savepoint. Die Nutzung der Journal-Vorlage sicherte Konsistenz.

---

## 6. Diskussion

### 6.1 Charakter der Methode

Promptotyping ist ein pragmatischer Ansatz, der aus der Praxis entstand. Die Methode dokumentiert funktionierende Praktiken aus realen Projekten. Sie macht implizites Wissen explizit und teilbar durch strukturierte Dokumentation. Die Phasenstruktur reduziert kognitive Last durch klare Aufgabenteilung. Das Savepoint-System erm√∂glicht kontrollierte Iteration. Expertenvalidierung sichert fachliche Qualit√§t.

### 6.2 Grenzen und Einschr√§nkungen

Die dokumentierten Praktiken basieren auf Projekterfahrungen, nicht auf kontrollierten Studien. Genannte Grenzen sind kontextabh√§ngige Beobachtungen aus unserer Praxis.

Browser-basierte Prototypen sto√üen bei komplexen Datenmengen an Performance-Grenzen. Das Kriminalmuseum Canvas-Interface mit 3.892 Objekten und REALonline Treemaps zeigten Limitierungen bei komplexen Visualisierungen. Die konkrete Grenze h√§ngt von Datenstruktur, Visualisierungstyp und Client-Hardware ab.

Basierend auf unserer Erfahrung: Optimale Dokumentenanzahl liegt bei 5-7. Lucina mit √ºber elf Dokumenten demonstrierte, dass die Navigation zwischen Dokumenten ab etwa zehn Dokumenten die Entwicklung verlangsamt. Stefan Zweig ohne Dokumente und Kriminalmuseum mit drei Dokumenten zeigen, dass unter f√ºnf Dokumenten die Nachvollziehbarkeit leidet. Lucina's f√ºnf Versionen offenbarten zudem Bedarf f√ºr systematisches Versions-Management jenseits von Git.

Die Methode ist f√ºr explorative Prototypen optimiert und nicht f√ºr Produktivsysteme geeignet. Langzeitwartbarkeit ohne formale Tests ist problematisch. Der √úbergang zu einer professionellen Entwicklung erfordert zus√§tzliche Schritte. Beispiele hierf√ºr sind Code Reviews. Hier wollen wir aber nichts versprechen und empfehlen. Wir sehen durchaus auch die M√∂glichkeit einer Professionalisierung der Software und der Produktfertigkeit.

### 6.3 Anwendungsempfehlungen

Basierend auf unseren Erfahrungen eignet sich Promptotyping f√ºr explorative Forschungsprojekte mit unklaren Requirements, Proof-of-Concepts f√ºr F√∂rderantr√§ge, Prototypen zur Stakeholder-Kommunikation, Werkzeuge f√ºr projektspezifische Datenanalyse und didaktische Demonstrationen in der Lehre.

Weniger geeignet erscheint die Methode f√ºr Produktivsysteme mit Langzeitanforderungen, sicherheitskritische Anwendungen, Datenverarbeitung mit rechtlichen Anforderungen, Teams ohne dedizierte Experten und Projekte mit strikten Performance-Anforderungen.

---

## 7. Verwandte Arbeiten

W√§hrend umfassende Methodologien f√ºr LLM-assistierte Entwicklung noch fehlen, existieren relevante Vorarbeiten.

Zhou et al. (2023) systematisieren Prompt-Optimierung, fokussieren aber auf Einzelprompts statt Entwicklungsprozesse. Promptotyping erweitert dies auf mehrstufige Entwicklung. Chen et al. (2021) evaluieren Codex, Peng et al. (2023) messen GitHub Copilot Produktivit√§t. Beide untersuchen Werkzeuge, nicht Methoden. Promptotyping bietet einen methodischen Rahmen f√ºr diese Werkzeuge.

Drucker (2009) argumentiert f√ºr "Rapid Prototyping" in Digital Humanities. Ramsay (2011) fordert "Algorithmic Criticism". Promptotyping operationalisiert diese Konzepte f√ºr die LLM-√Ñra. Das Spiral Model (Boehm, 1988) inspirierte die iterative Struktur, wurde aber f√ºr LLM-Charakteristika angepasst. Agile Methoden beeinflussten die Dokumentations-leichte Philosophie.

Promptotyping unterscheidet sich durch den Fokus auf strukturierte Dokumentation als externes Arbeitsged√§chtnis, mehrstufige Validierung und explizite Savepoints in explorativen Kontexten.

---

## 8. Fazit

Promptotyping bietet einen pragmatischen Ansatz f√ºr LLM-assistierte Entwicklung in den Digital Humanities. Die aus der Praxis entwickelte Sechsphasenstruktur mit kritischer IMPLEMENTATION-Phase half in unseren Projekten, typische Fehlerquellen zu vermeiden. Das Savepoint-System erm√∂glicht kontrollierte Iteration mit Expertenvalidierung. Mehrstufige Validierung kombiniert menschliche Expertise mit automatisierter Verifikation.

Die Methode ist explizit f√ºr explorative Prototypen konzipiert, nicht f√ºr Produktivsysteme. Sie erm√∂glicht niedrigschwellige technische Entwicklung ohne Programmier-Vorkenntnisse bei gleichzeitiger Wahrung wissenschaftlicher Standards durch strukturierte Dokumentation und nachvollziehbare Entscheidungsprozesse.

Die sieben Fallstudien demonstrieren praktische Anwendbarkeit √ºber verschiedene DH-Dom√§nen. Von Timeline-Tools √ºber Treemap-Visualisierungen bis zu digitalen Editionen entstanden funktionale Prototypen. In unserer Erfahrung zeigten Projekte von acht bis zehn Stunden Umfang mit f√ºnf bis sieben Dokumenten eine gute Balance zwischen Struktur und Agilit√§t. Die kritische IMPLEMENTATION-Phase und kontinuierliche Expertenvalidierung an Savepoints erwiesen sich als besonders wertvoll.

Alle entwickelten Prototypen sind als Open Source mit vollst√§ndiger Dokumentation verf√ºgbar. Die lauff√§higen Demos demonstrieren die Praxistauglichkeit der Methode und dienen als Lernressourcen f√ºr eigene Projekte.

Zuk√ºnftige Arbeiten k√∂nnten den √úbergang von Prototypen zu Produktivsystemen systematisieren, automatische Tests aus IMPLEMENTATION-Dokumenten generieren und Kollaborationsmechanismen f√ºr gr√∂√üere Teams entwickeln. Eine systematische Evaluation der Methode √ºber verschiedene Dom√§nen hinweg w√§re w√ºnschenswert. Die Integration in bestehende IDE-Umgebungen k√∂nnte die Adoption erleichtern.

---

## Literatur

Boehm, B. (1988). A Spiral Model of Software Development and Enhancement. *Computer*, 21(5), 61-72.

Chen, M., et al. (2021). Evaluating Large Language Models Trained on Code. arXiv:2107.03374.

Drucker, J. (2009). *SpecLab: Digital Aesthetics and Projects in Speculative Computing*. University of Chicago Press.

Karpathy, A. (2025). "Vibe Coding". Blog Post, 3. Februar 2025. https://karpathy.ai/blog/vibe-coding

Peng, S., et al. (2023). *The Impact of AI on Developer Productivity: Evidence from GitHub Copilot*. Microsoft Research.

Ramsay, S. (2011). *Reading Machines: Toward an Algorithmic Criticism*. University of Illinois Press.

Zhou, Y., et al. (2023). Large Language Models Are Human-Level Prompt Engineers. arXiv:2211.01910.

---

## Anhang A: Journal-Template

```markdown
# Promptotyping Journal: [Projektname]

**Ziel:** [Was wird gebaut]
**Ausgangslage:** [Vorhandene Dateien, Daten, Wissen]
**Start:** [Datum]
**Team:** [Beteiligte Personen und Rollen]

---

## [Datum] - [Phase] - [Sitzung Nr.]

### Kontext
[Beschreibung der Ausgangssituation und Zielsetzung dieser Sitzung]

### Vorgehen
**Modell:** [Verwendetes LLM und Begr√ºndung der Wahl]
**Input:** [Bereitgestellte Dokumente/Kontext]
**Werkzeuge:** [Verwendete Tools, IDEs, Libraries]

### Hauptaktivit√§t
**Phase:** [CONTEXT/DATA/EXPLORATION/REQUIREMENTS/IMPLEMENTATION/PROTOTYPE]
**Output:** [Generierte Dateien]

### Validierung
**Validator:** [Name und Rolle]
**Methode:** [Technische Pr√ºfung / Fachliche Pr√ºfung / LLM-as-Judge]
**Entscheidung:** [Akzeptiert / Modifiziert / Verworfen]
**Begr√ºndung:** [Detaillierte fachliche oder technische Einsch√§tzung]

### Probleme & L√∂sungen
- **Problem:** [Beschreibung]
- **L√∂sung:** [Wie gel√∂st]

### Erkenntnisse
- [Muster oder Heuristik, die sich bew√§hrt hat]
- [Was beim n√§chsten Mal anders gemacht werden sollte]

### N√§chste Schritte
- [Geplante Aktivit√§ten f√ºr die n√§chste Sitzung]

### Savepoint
‚òë Phase abgeschlossen
‚òë Dokumente erstellt: [Liste]
‚òê Expertenvalidierung erfolgt
‚òê Git-Commit: [Hash oder Tag]
```

---

## Anhang B: Beispiel-Prompts f√ºr jede Phase

### B.1 CONTEXT-Phase

```
Erstelle eine README.md f√ºr ein Tool zur [Zweck].

Kontext:
- Zielgruppe: [Spezifische Nutzergruppe mit Kenntnisstand]
- Hauptziel: [Was soll erreicht werden]
- Anwendungsfall: [Konkretes Szenario]
- Technische Constraints: [z.B. Browser-only, keine Server]
- Fachliche Constraints: [z.B. historische Korrektheit]

Die README sollte enthalten:
1. Projekttitel und Kurzbeschreibung
2. Zielgruppe und Voraussetzungen
3. Hauptfunktionalit√§ten (als User Stories)
4. Technische Rahmenbedingungen
5. Glossar wichtiger Fachbegriffe
```

### B.2 DATA-Phase

```
Analysiere die angeh√§ngte Datendatei/Struktur und erstelle eine DATA.md mit:

1. Datenformat und Struktur (Schema)
2. Identifizierte Datentypen pro Feld
3. Inkonsistenzen oder Anomalien
4. Fehlende oder optionale Felder
5. Beziehungen zwischen Datenelementen
6. Statistische √úbersicht (Anzahl Eintr√§ge, Wertebereiche)
7. Empfohlene Normalisierungen
8. Beispiel-Datens√§tze (min. 3 repr√§sentative)

Markiere besonders kritische Datentransformationen, die sp√§ter
in IMPLEMENTATION dokumentiert werden m√ºssen.
```

### B.3 REQUIREMENTS-Phase

```
Basierend auf README.md und den Erkenntnissen aus EXPLORATION,
erstelle eine REQUIREMENTS.md mit:

## Funktionale Anforderungen (nach Priorit√§t)
- MUSS: [Kritische Features]
- SOLL: [Wichtige Features]
- KANN: [Nice-to-have Features]

## Nicht-funktionale Anforderungen
- Performance: [z.B. Ladezeiten, Responsiveness]
- Kompatibilit√§t: [Browser, Ger√§te]
- Usability: [z.B. ohne Einarbeitung nutzbar]
- Accessibility: [WCAG-Standards]

## Explizite Ausschl√ºsse
[Was das System NICHT k√∂nnen muss]

Formuliere jede Anforderung als testbaren Satz.
```

### B.4 IMPLEMENTATION-Phase

```
Erstelle INSTRUCTIONS.md basierend auf REQUIREMENTS.md und DATA.md.

Dokumentiere f√ºr jede Anforderung:

## Feature: [Name]
### Datentransformation
- Input: [Rohdatenformat]
- Transformationsschritte: [Pr√§zise Algorithmen]
- Output: [Zielformat]
- Edge Cases: [Sonderf√§lle und deren Behandlung]

### Validierungen
- [Welche Pr√ºfungen vor Verarbeitung]
- [Fehlerbehandlung]

### UI/UX-Spezifikation
- [Interaktionsmuster]
- [Visuelles Verhalten]
- [Responsive Design Breakpoints]

### Code-Struktur
- [Empfohlene Komponenten/Module]
- [State Management Ansatz]
- [Wichtige Funktionen mit Signaturen]

WICHTIG: Dokumentiere ALLE Stellen, wo Datentypen
variieren k√∂nnen (Array vs. Einzelwert etc.)
```

### B.5 PROTOTYPE-Phase

```
Generiere eine vollst√§ndige, lauff√§hige Implementierung basierend auf:
- INSTRUCTIONS.md (prim√§re Spezifikation)
- REQUIREMENTS.md (f√ºr Priorit√§ten)
- DATA.md (f√ºr Datenstrukturen)

Technische Vorgaben:
- Single HTML File mit inline CSS/JS
- Keine externen Dependencies au√üer CDN-verf√ºgbare
- Responsive Design (Mobile-first)
- Kommentierter Code an kritischen Stellen

Der Code muss:
1. Alle MUSS-Anforderungen erf√ºllen
2. Die dokumentierten Datentransformationen implementieren
3. Robuste Fehlerbehandlung haben
4. Die spezifizierten Validierungen durchf√ºhren

Beginne mit einem funktionsf√§higen Minimal-Prototyp und erweitere
schrittweise.
```

---

## Anhang C: Projektstruktur

```
project/
‚îú‚îÄ‚îÄ README.md           # CONTEXT
‚îú‚îÄ‚îÄ DATA.md            # Datenspezifikation
‚îú‚îÄ‚îÄ REQUIREMENTS.md    # Anforderungen
‚îú‚îÄ‚îÄ INSTRUCTIONS.md    # Implementierung
‚îú‚îÄ‚îÄ JOURNAL.md         # Entwicklungsprotokoll
‚îú‚îÄ‚îÄ data/              # Rohdaten
‚îÇ   ‚îî‚îÄ‚îÄ sample.json
‚îú‚îÄ‚îÄ exploration/       # Experimente
‚îÇ   ‚îî‚îÄ‚îÄ test-01.html
‚îú‚îÄ‚îÄ prototype/         # Finaler Code
‚îÇ   ‚îî‚îÄ‚îÄ index.html
‚îî‚îÄ‚îÄ .git/             # Versionskontrolle
```
